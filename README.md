This aims to provide the deaf with an affordable solution for their day-to-day communication activities with the general public.

Being an advocate of participating in inclusive initiatives as a completely blind person myself, this project can assist them when they need to talk to persons who are not deaf and do not know how to use sign language.

I want a solution that won't require them to take out their smartphones, especially in certain neighborhoods here in Metro Manila (my blindness was caused by an incident of senseless violence).

Right now, this translates voice input into sign language, which is shown to the user through the virtual display of a semi-transparent OLED lens.
I used the Microsoft CIS Speech API for speech-to-text conversion, and a script to convert text into finger-spelled ASL (American Sign Language).

Notes:  For the past several years, I have participated in various activities for persons with disabilities (PWDs).
-  And, I learned  that many of the deaf are not comfortable reading voluminous text during lengthy conversations.
-  So instead, lots of them prefer sign language over reading text.
-  But they are quite familiar in writing text when communicating with non-deaf persons.
-  Though of course, they still prefer using sign language to converse with non-deaf persons.

And this is why I'm still working on offline ASL gesture detection and recognition.
This is to use the camera of these eyeglasses to detect, recognize and convert the user's ASL gestures into spoken audio for the other person to hear.

So I'll continue to fine-tune a Mask RCNN model for this.
And, I'll further optimize the hardware components and software features of my project.
